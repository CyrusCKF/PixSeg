{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and visualize images/video with overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms.v2 import functional as TF\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "from src.pixseg.datasets import *\n",
    "from src.pixseg.models import *\n",
    "from src.pixseg.pipeline import TestTimeAugmentations, inference_with_augmentations\n",
    "from src.pixseg.utils.transform import SegmentationAugment, SegmentationTransform\n",
    "from src.pixseg.utils.visual import combine_images, draw_mask_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://www.pexels.com/video/vehicle-on-highway-with-dash-cam-4608285/\n",
    "VIDEO_PATH = Path(r\"..\\assets\\4608285-uhd_3840_2160_24fps.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = resolve_metadata(\"Cityscapes\")\n",
    "transforms = SegmentationTransform(mask_fill=metadata.ignore_index)\n",
    "augment = SegmentationAugment(mask_fill=metadata.ignore_index)\n",
    "model = sfnet_resnet101(weights=SFNet_ResNet101_Weights.CITYSCAPES)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 4\n",
    "frame_size = (1280, 720)\n",
    "ttas = TestTimeAugmentations(\n",
    "    (0.75, 1, 1.25), (False, True), (False,), (-15, 0, 15), iter_product=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frames(capture: cv2.VideoCapture):\n",
    "    while capture.isOpened():\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        yield frame\n",
    "\n",
    "\n",
    "def video_to_tensor(video_file: str, size: tuple[int, int] | None = None) -> Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        size: tuple of (width, height)\n",
    "\n",
    "    Return:\n",
    "        video tensor of (num_frames, height, width, channels)\n",
    "    \"\"\"\n",
    "    capture = cv2.VideoCapture(video_file)\n",
    "    if not capture.isOpened():\n",
    "        raise RuntimeError(\"Error opening video file\")\n",
    "\n",
    "    frames: list[Tensor] = []\n",
    "    num_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))  # reference only\n",
    "    frame_loader = tqdm(generate_frames(capture), \"Load video\", num_frames)\n",
    "    for frame in frame_loader:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        if size is not None:\n",
    "            frame = cv2.resize(frame, size)\n",
    "        frame_tensor = torch.from_numpy(frame)\n",
    "        frames.append(frame_tensor)\n",
    "\n",
    "    capture.release()\n",
    "    video_tensor = torch.stack(frames)\n",
    "    return video_tensor\n",
    "\n",
    "\n",
    "def tensor_to_video(frames: Tensor, output_file: str, fps=24):\n",
    "    num_frames, channels, height, width = frames.shape\n",
    "    video_writer = cv2.VideoWriter(output_file, 0, fps, (width, height))\n",
    "\n",
    "    frame_loader = tqdm(frames, \"Write video\", num_frames)\n",
    "    for frame in frame_loader:\n",
    "        # (C, H, W) -> (H, W, C)\n",
    "        frame = frame.permute(1, 2, 0)\n",
    "        frame = TF.to_dtype(frame, torch.uint8, scale=True)\n",
    "        frame_np = cv2.cvtColor(frame.numpy(force=True), cv2.COLOR_RGB2BGR)\n",
    "        video_writer.write(frame_np)\n",
    "\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = video_to_tensor(str(VIDEO_PATH), frame_size)\n",
    "frames = frames.permute(0, 3, 1, 2)  # (F, H, W, C) -> (F, C, H, W)\n",
    "print(frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval().to(device)\n",
    "dataset = TensorDataset(frames)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "batch_preds: list[Tensor] = []\n",
    "with torch.no_grad():\n",
    "    for (data,) in tqdm(data_loader):\n",
    "        data = transforms(data)[0].to(device)\n",
    "        augmented_logits = inference_with_augmentations(model, data, ttas)\n",
    "        logits = torch.mean(augmented_logits, dim=0)\n",
    "        batch_preds.append(logits.argmax(1).cpu())\n",
    "preds = torch.cat(batch_preds, dim=0)\n",
    "print(frames.shape, preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 5\n",
    "colors = metadata.colors\n",
    "pred_overlay = draw_mask_on_image(frames[index], preds[index], colors)\n",
    "snapshot = combine_images([frames[index], pred_overlay])\n",
    "snapshot_pil: PIL.Image.Image = TF.to_pil_image(snapshot)\n",
    "display(snapshot_pil.reduce(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_frames: list[Tensor] = []\n",
    "for frame, pred in tqdm(zip(frames, preds), \"Draw mask\", frames.size(0)):\n",
    "    overlay = draw_mask_on_image(frame, pred, colors)\n",
    "    output_frame = combine_images([frame, overlay], nrow=1)\n",
    "    output_frames.append(output_frame)\n",
    "output_video = torch.stack(output_frames)\n",
    "output_path = VIDEO_PATH.parent / f\"{VIDEO_PATH.stem}-parse.avi\"\n",
    "tensor_to_video(output_video, str(output_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
