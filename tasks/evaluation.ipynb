{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from timeit import default_timer\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "from src.semantic_segmentation_toolkit.datasets import resolve_metadata\n",
    "from src.semantic_segmentation_toolkit.models import FCN_ResNet34_Weights, fcn_resnet34\n",
    "from src.semantic_segmentation_toolkit.pipeline import (\n",
    "    TesttimeAugmentations,\n",
    "    eval_one_epoch,\n",
    "    inference_with_augmentations,\n",
    ")\n",
    "from src.semantic_segmentation_toolkit.utils.metrics import MetricStore\n",
    "from src.semantic_segmentation_toolkit.utils.transform import SegmentationTransform\n",
    "from src.semantic_segmentation_toolkit.utils.rng import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = FCN_ResNet34_Weights.VOC2012\n",
    "model = fcn_resnet34(weights=weights)\n",
    "transforms = SegmentationTransform()\n",
    "augment = weights.value.transforms()\n",
    "dataset = VOCSegmentation(\n",
    "    r\"..\\dataset\", image_set=\"val\", transforms=transforms, year=\"2007\"\n",
    ")\n",
    "data_loader = DataLoader(dataset)\n",
    "metadata = resolve_metadata(\"VOC\")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=metadata.ignore_index)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 213/213 [00:23<00:00,  9.06it/s, acc=0.916, macc=0.725, miou=0.626, fwiou=0.851, dice=0.752, loss=0.282, time=0.0812]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.916085298055659,\n",
      " 'dice': 0.7518140231973609,\n",
      " 'fwiou': 0.8508206689830995,\n",
      " 'loss': 0.2819842651416438,\n",
      " 'macc': 0.724729110277966,\n",
      " 'miou': 0.626465678574391,\n",
      " 'time': 0.0811527868592893}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "ms = eval_one_epoch(\n",
    "    model, data_loader, augment, criterion, device, metadata.num_classes\n",
    ")\n",
    "pprint(ms.summarize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttas = TesttimeAugmentations(\n",
    "    (0.75, 1, 1.25), (False, True), (False,), (0,), iter_product=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [02:22<00:00,  1.49it/s, acc=0.92, macc=0.713, miou=0.636, fwiou=0.856, dice=0.755, loss=0.269, time=0.646]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.9200380417427184,\n",
      " 'dice': 0.7545043196274661,\n",
      " 'fwiou': 0.8555621297554995,\n",
      " 'loss': 0.26908271920653015,\n",
      " 'macc': 0.7132025147834363,\n",
      " 'miou': 0.6355080084597899,\n",
      " 'time': 0.6462920990536435}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "model.to(device).eval()\n",
    "ms = MetricStore(metadata.num_classes)\n",
    "loader = tqdm.tqdm(iter(data_loader), total=len(data_loader))\n",
    "for images, masks in loader:\n",
    "    start_time = default_timer()\n",
    "    prelim_images, masks = augment(images.to(device), masks)\n",
    "    augmented_logits = inference_with_augmentations(model, prelim_images, ttas)\n",
    "    aggregated_logits = torch.mean(augmented_logits, dim=0)\n",
    "    loss = criterion(aggregated_logits, masks)\n",
    "    end_time = default_timer()\n",
    "\n",
    "    preds = aggregated_logits.argmax(1)\n",
    "    ms.store_results(masks, preds)\n",
    "    batch_size = images.size(0)\n",
    "    measures = {\n",
    "        \"loss\": loss.item() * batch_size,\n",
    "        \"time\": end_time - start_time,\n",
    "    }\n",
    "    ms.store_measures(batch_size, measures)\n",
    "    loader.set_postfix(ms.summarize())\n",
    "pprint(ms.summarize())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
