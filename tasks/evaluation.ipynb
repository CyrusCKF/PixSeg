{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model using these strategies\n",
    "\n",
    "Each technique adds significant time cost. You may play around which combos give the best balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRFs and Morphological Operations\n",
    "\n",
    "Refine boundaries and clean up noises\n",
    "\n",
    "Use PyDenseCRF, employ dilation and erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding\n",
    "\n",
    "Fine tune uncertain regions around boundaries\n",
    "\n",
    "Apply threshold on logits after softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-Time Augmentation and Multi-Scale\n",
    "\n",
    "Improve robustness and accuracy, reduce reliance on specific features\n",
    "\n",
    "Apply augmentations like flipping, rotation, scaling, etc ... Then aggregate results by max/most/mean/weighted on logits/probs/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL.Image import Image\n",
    "from pydensecrf import densecrf as dcrf  # type: ignore\n",
    "from pydensecrf.utils import unary_from_softmax\n",
    "from scipy.ndimage import binary_dilation, binary_erosion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import Tensor\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision.transforms.v2 import functional as TF\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "from src.datasets import resolve_metadata\n",
    "from src.models import FCN_ResNet34_Weights, fcn_resnet34\n",
    "from src.pipeline import forward_batch\n",
    "from src.utils.metrics import metrics_from_confusion\n",
    "from src.utils.transform import DataTransform\n",
    "from src.utils.visual import combine_images, draw_mask_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_segmentation_with_crf_and_morphology(\n",
    "    logits, image, apply_crf=True, apply_morphology=True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Refine semantic segmentation logits using CRF and morphological operations.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): Logits tensor of shape (num_class, H, W).\n",
    "        image (np.ndarray): Original image as a NumPy array of shape (H, W, 3).\n",
    "        apply_crf (bool): Whether to apply CRF.\n",
    "        apply_morphology (bool): Whether to apply morphological operations.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Refined segmentation map of shape (H, W).\n",
    "    \"\"\"\n",
    "    H, W = logits.shape[1], logits.shape[2]\n",
    "    num_classes = logits.shape[0]\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probs = torch.softmax(logits, dim=0).cpu().numpy()  # Shape: (num_class, H, W)\n",
    "    predicted_mask = np.argmax(probs, axis=0)  # Initial prediction, shape: (H, W)\n",
    "\n",
    "    # Apply CRF\n",
    "    if apply_crf:\n",
    "        d = dcrf.DenseCRF2D(W, H, num_classes)  # Initialize CRF\n",
    "        unary = unary_from_softmax(probs)  # Convert probabilities to unary potentials\n",
    "        d.setUnaryEnergy(unary)\n",
    "\n",
    "        # Add pairwise terms using the image\n",
    "        d.addPairwiseGaussian(sxy=3, compat=3)  # Spatial smoothness\n",
    "        d.addPairwiseBilateral(\n",
    "            sxy=50, srgb=13, rgbim=image, compat=10\n",
    "        )  # Appearance-based smoothness\n",
    "\n",
    "        # Perform CRF inference\n",
    "        refined_probs = np.array(d.inference(10)).reshape(\n",
    "            num_classes, H, W\n",
    "        )  # Refined probabilities\n",
    "        predicted_mask = np.argmax(refined_probs, axis=0)  # Update prediction\n",
    "\n",
    "    # Apply morphological operations\n",
    "    if apply_morphology:\n",
    "        binary_mask = (predicted_mask > 0).astype(\n",
    "            np.uint8\n",
    "        )  # Binary mask for non-background\n",
    "        binary_mask = binary_dilation(binary_mask, iterations=1)  # Dilation\n",
    "        binary_mask = binary_erosion(binary_mask, iterations=1)  # Erosion\n",
    "\n",
    "        # Apply the refined binary mask to the predicted mask\n",
    "        predicted_mask[binary_mask == 0] = 0\n",
    "\n",
    "    return predicted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_thresholding(logits, threshold=0.5, uncertain=255):\n",
    "    \"\"\"\n",
    "    Apply thresholding to refine class boundaries in semantic segmentation.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): Logits tensor of shape (num_class, H, W).\n",
    "        threshold (float): Confidence threshold (between 0 and 1).\n",
    "        uncertain: index for uncertain regions\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Refined segmentation map of shape (H, W).\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities\n",
    "    probs = torch.softmax(logits, dim=0)  # Shape: (num_class, H, W)\n",
    "\n",
    "    # Get the predicted class for each pixel\n",
    "    predicted_classes = torch.argmax(probs, dim=0)  # Shape: (H, W)\n",
    "\n",
    "    # Apply thresholding\n",
    "    max_probs, _ = torch.max(probs, dim=0)  # Maximum probability for each pixel\n",
    "    refined_mask = torch.where(max_probs >= threshold, predicted_classes, uncertain)\n",
    "\n",
    "    return refined_mask  # Shape: (H, W), where 255 indicates uncertain pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = FCN_ResNet34_Weights.VOC2012\n",
    "model = fcn_resnet34(weights=weights)\n",
    "transforms = DataTransform()\n",
    "augment = weights.value.transforms()\n",
    "dataset = VOCSegmentation(r\"D:\\_Dataset\", image_set=\"val\", transforms=transforms)\n",
    "metadata = resolve_metadata(\"VOC\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: tuple[Tensor, Tensor] = dataset[1]\n",
    "image, mask = data\n",
    "model.eval().to(device)\n",
    "with torch.no_grad():\n",
    "    images, masks = image.unsqueeze(0), mask.unsqueeze(0)\n",
    "    logits, _ = forward_batch(model, images, masks, augment, None, device)\n",
    "logit = logits[\"out\"].squeeze(0)\n",
    "pred = logit.argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = metadata.colors\n",
    "mask_overlay = draw_mask_on_image(image, mask, colors)\n",
    "pred_overlay = draw_mask_on_image(image, pred, colors)\n",
    "\n",
    "crf_image = (\n",
    "    TF.to_dtype(image, torch.uint8, scale=True)\n",
    "    .permute(1, 2, 0)\n",
    "    .contiguous()\n",
    "    .numpy(force=True)\n",
    ")\n",
    "refined_arr = refine_segmentation_with_crf_and_morphology(logit, crf_image)\n",
    "refined = torch.tensor(refined_arr, dtype=torch.uint8)\n",
    "refined_overlay = draw_mask_on_image(image, refined, colors)\n",
    "\n",
    "# combined = combine_images([image, mask_overlay, pred_overlay, refined_overlay])\n",
    "# combined_pil: Image = TF.to_pil_image(combined)\n",
    "# display(combined_pil.reduce(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55254    27  8570]\n",
      " [    0     0     0]\n",
      " [ 8262  7731 77660]]\n",
      "{'acc': 0.8438769809020723,\n",
      " 'dice': 0.5770282016901661,\n",
      " 'fwiou': 0.7623476883155276,\n",
      " 'macc': 0.5648632412873146,\n",
      " 'miou': 0.5086419156730985}\n",
      "[[52617     0 11234]\n",
      " [    0     0     0]\n",
      " [10547  1364 81742]]\n",
      "{'acc': 0.8530513510767981,\n",
      " 'dice': 0.5681667402847043,\n",
      " 'fwiou': 0.7501062599352178,\n",
      " 'macc': 0.5656256265827229,\n",
      " 'miou': 0.4955235678430326}\n"
     ]
    }
   ],
   "source": [
    "ignore_index = metadata.ignore_index\n",
    "mask_np = mask.numpy(force=True).flatten()\n",
    "pred_np = pred.numpy(force=True).flatten()\n",
    "not_ignored = (mask_np != ignore_index) & (pred_np != ignore_index)\n",
    "\n",
    "cm = confusion_matrix(mask_np[not_ignored], pred_np[not_ignored])\n",
    "print(cm)\n",
    "pprint(metrics_from_confusion(cm))\n",
    "\n",
    "refined_np = refined.numpy(force=True).flatten()\n",
    "not_ignored = (mask_np != ignore_index) & (refined_np != ignore_index)\n",
    "\n",
    "cm = confusion_matrix(mask_np[not_ignored], refined_np[not_ignored])\n",
    "print(cm)\n",
    "pprint(metrics_from_confusion(cm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
