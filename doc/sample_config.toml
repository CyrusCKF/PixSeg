# Notes: 
# 1. When batch_size > 1, make sure images all have same size OR pad_crop_size to not "none" 
# 2. If batch_size = 1, some model using batch norm in train mode will raise error

[model]
model = "deeplabv3_mobilenet_v3_large"
# state_file = './model.pth'             # uncomment to load model state dict
params = {}

[data.dataset]
dataset = "VOC"
pad_crop_size = [500, 500]                      # "none", or tuple of (H, W)
params = { root = '..\dataset', year = "2007" }

[data.loader]
num_workers = 0
params = { batch_size = 2, drop_last = true, shuffle = true }

[data.augment]
params = { hflip = 0.5 }

[criterion]
criterion = "CrossEntropyLoss"
class_weight = "none"          # name of list of floats
aux_weight = 0
params = {}

[optimizer]
optimizer = "SGD"
effective_batch_size = 32                                   # must be multiple of batch_size
params = { lr = 3e-4, momentum = 0.9, weight_decay = 5e-4 }

[lr_scheduler]
lr_scheduler = "StepLR"
params = { step_size = 20, gamma = 0.1 }

[scaler]
params = {}

[trainer]
device = "auto"
params = { num_epochs = 50, checkpoint_steps = 5 }

[paths]
runs_folder = '..\runs'
# checkpoint = '../runs/exp1/latest_checkpoint.pth' # uncomment to resume checkpoint

[log.wandb]
# api_key = "ssssssssssssssssssssssssssssssssssssssss" # uncomment to use wandb
# run_id = "ssssssss" # uncomment to resume run
params = { project = "Semantic-Segmentation", job_type = "train", dir = '..\' }

[log.tensorboard]
enabled = false
params = { parent_dir = '..\tensorboard' }
